{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as mltp\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "import sklearn as sk\n",
    "import seaborn as sea\n",
    "import re \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classifier \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mzero-shot-classification\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['climate',\n",
    "'economy',\n",
    "'education',\n",
    "'health',\n",
    "'infrastructure',\n",
    "'science',\n",
    "'social causes',\n",
    "'politics and ideology',\n",
    "'technology and entrepreneurship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "nli_model.to(mps_device)\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n",
      "  warnings.warn(\n",
      "/Users/niclascramer/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/functional.py:864: UserWarning: The operator 'aten::unique_consecutive' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1671696763866/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  output, inverse_indices, counts = _VF.unique_consecutive(  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "sequence_to_classify = \"one day I will see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "premise = sequence_to_classify\n",
    "hypothesis = f'This example is {candidate_labels}.'\n",
    "\n",
    "# run through model pre-trained on MNLI\n",
    "x = tokenizer.encode(premise, hypothesis, return_tensors='pt',\n",
    "                     truncation_strategy='only_first')\n",
    "logits = nli_model(x.to(mps_device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2638,  0.6775, -1.0134]], device='mps:0',\n",
       "       grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we throw away \"neutral\" (dim 1) and take the probability of\n",
    "# \"entailment\" (2) as the probability of the label being true \n",
    "entail_contradiction_logits = logits\n",
    "probs = entail_contradiction_logits.softmax(dim=1)\n",
    "prob_label_is_true = probs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5418], device='mps:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_label_is_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_bcandidate_labels = [\"positive\", \"negative\",'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I hated this movie. The acting sucked.',\n",
       " 'labels': ['negative', 'neutral', 'positive'],\n",
       " 'scores': [0.9757519960403442, 0.016008835285902023, 0.008239180780947208]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"I hated this movie. The acting sucked.\"\n",
    "classifier(sequence, class_bcandidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'The movie was 100 minutes long, with no pause.',\n",
       " 'labels': ['negative', 'positive', 'neutral'],\n",
       " 'scores': [0.3668157756328583, 0.34670284390449524, 0.28648144006729126]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"The movie was 100 minutes long, with no pause.\"\n",
    "classifier(sequence, class_bcandidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `multi_class` argument has been deprecated and renamed to `multi_label`. `multi_class` will be removed in a future version of Transformers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Die Wirtschaft verlief gut',\n",
       " 'labels': ['economy',\n",
       "  'infrastructure',\n",
       "  'technology and entrepreneurship',\n",
       "  'health',\n",
       "  'science',\n",
       "  'social causes',\n",
       "  'climate',\n",
       "  'education',\n",
       "  'politics and ideology'],\n",
       " 'scores': [0.9657909870147705,\n",
       "  0.13397930562496185,\n",
       "  0.024615313857793808,\n",
       "  0.0004468511324375868,\n",
       "  0.0003251165908295661,\n",
       "  0.000202704148250632,\n",
       "  0.00012562797928694636,\n",
       "  8.024831186048687e-05,\n",
       "  2.9401642677839845e-05]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"Die Wirtschaft verlief gut\"\n",
    "\n",
    "\n",
    "classifier(sequence, labels, multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_2 = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `multi_class` argument has been deprecated and renamed to `multi_label`. `multi_class` will be removed in a future version of Transformers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Die Wirtschaft verlief gut',\n",
       " 'labels': ['economy',\n",
       "  'infrastructure',\n",
       "  'technology and entrepreneurship',\n",
       "  'health',\n",
       "  'science',\n",
       "  'social causes',\n",
       "  'climate',\n",
       "  'education',\n",
       "  'politics and ideology'],\n",
       " 'scores': [0.9657909870147705,\n",
       "  0.13397930562496185,\n",
       "  0.024615313857793808,\n",
       "  0.0004468511324375868,\n",
       "  0.0003251165908295661,\n",
       "  0.000202704148250632,\n",
       "  0.00012562797928694636,\n",
       "  8.024831186048687e-05,\n",
       "  2.9401642677839845e-05]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"Die Wirtschaft verlief gut\"\n",
    "\n",
    "\n",
    "classifier_2(sequence, labels, multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization_test(texts,  allowed_posttags=['NOUN','ADJ','VERB','ADV']):\n",
    "    nlp=spacy.load('en_core_web_sm',disable=['parser','ner'])\n",
    "    texts_out=[]\n",
    "    for text in tqdm(texts):\n",
    "        doc= nlp(text)\n",
    "        new_text=[]\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_posttags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final=' '.join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return texts_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54c35701683d52397dec8c1b1dabb7d7599bf83c9aec0584240eb3e578830d84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
